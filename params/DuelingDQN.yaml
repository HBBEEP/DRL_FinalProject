DuelingDQN : 
  experiment_1:
    save_path : output\DuelingDQN_policy_exp1
    n_episodes : 10
    target_update_interval : 1
    initial_epsilon : 1.0
    epsilon_decay : 0.998
    final_epsilon : 0.05
    learning_rate : 0.001
    discount_factor :  0.99
    tau : 0.95
    batch_size : 8
    buffer_size : 100

  experiment_2:
    save_path : output\DuelingDQN_policy_exp2
    n_episodes : 100
    target_update_interval : 1
    initial_epsilon : 1.0
    epsilon_decay : 0.998
    final_epsilon : 0.05
    learning_rate : 0.001
    discount_factor :  0.99
    tau : 0.95
    batch_size : 8
    buffer_size : 100

  experiment_3:
    save_path : output\DuelingDQN_policy_exp3
    n_episodes : 10
    target_update_interval : 1
    initial_epsilon : 1.0
    epsilon_decay : 0.998
    final_epsilon : 0.05
    learning_rate : 0.001
    discount_factor :  0.99
    tau : 0.95
    batch_size : 8
    buffer_size : 100

  play_1:
    n_episodes : 10
    policy_network_weight : network_weight
    target_network_weight : network_weight
    target_update_interval : 1
    initial_epsilon : 1.0
    epsilon_decay : 0.998
    final_epsilon : 0.05
    learning_rate : 0.001
    discount_factor :  0.99
    tau : 0.95
    batch_size : 8
    buffer_size : 100